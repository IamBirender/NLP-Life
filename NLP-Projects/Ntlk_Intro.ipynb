{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nltk book is here: http://www.nltk.org/book/\n",
    "\n",
    "NLP applications: http://blog.mashape.com/list-of-25-natural-language-processing-apis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a sentence, and we want to extract all the words from it.\n",
    "sentence = '''I charged the phone completely out of the box and then turned it on. It went to the Oneplus logo screen but did nothing after that. No buttons work, no combinations of any buttons do anything to take it out of logo screen, it won't even turn off. Amazon won't allow return until technician looks at the phone??? Oneplus support said take it to a service center but couldn't tell me the closest one. Really disappointed in lack of support form both companies for a brand new product and release. I'm sure they will now try to push a replacement but I'm not really interested in the product anymore.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'charged',\n",
       " 'the',\n",
       " 'phone',\n",
       " 'completely',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'box',\n",
       " 'and',\n",
       " 'then',\n",
       " 'turned',\n",
       " 'it',\n",
       " 'on.',\n",
       " 'It',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Oneplus',\n",
       " 'logo',\n",
       " 'screen',\n",
       " 'but',\n",
       " 'did',\n",
       " 'nothing',\n",
       " 'after',\n",
       " 'that.',\n",
       " 'No',\n",
       " 'buttons',\n",
       " 'work,',\n",
       " 'no',\n",
       " 'combinations',\n",
       " 'of',\n",
       " 'any',\n",
       " 'buttons',\n",
       " 'do',\n",
       " 'anything',\n",
       " 'to',\n",
       " 'take',\n",
       " 'it',\n",
       " 'out',\n",
       " 'of',\n",
       " 'logo',\n",
       " 'screen,',\n",
       " 'it',\n",
       " \"won't\",\n",
       " 'even',\n",
       " 'turn',\n",
       " 'off.',\n",
       " 'Amazon',\n",
       " \"won't\",\n",
       " 'allow',\n",
       " 'return',\n",
       " 'until',\n",
       " 'technician',\n",
       " 'looks',\n",
       " 'at',\n",
       " 'the',\n",
       " 'phone???',\n",
       " 'Oneplus',\n",
       " 'support',\n",
       " 'said',\n",
       " 'take',\n",
       " 'it',\n",
       " 'to',\n",
       " 'a',\n",
       " 'service',\n",
       " 'center',\n",
       " 'but',\n",
       " \"couldn't\",\n",
       " 'tell',\n",
       " 'me',\n",
       " 'the',\n",
       " 'closest',\n",
       " 'one.',\n",
       " 'Really',\n",
       " 'disappointed',\n",
       " 'in',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'support',\n",
       " 'form',\n",
       " 'both',\n",
       " 'companies',\n",
       " 'for',\n",
       " 'a',\n",
       " 'brand',\n",
       " 'new',\n",
       " 'product',\n",
       " 'and',\n",
       " 'release.',\n",
       " \"I'm\",\n",
       " 'sure',\n",
       " 'they',\n",
       " 'will',\n",
       " 'now',\n",
       " 'try',\n",
       " 'to',\n",
       " 'push',\n",
       " 'a',\n",
       " 'replacement',\n",
       " 'but',\n",
       " \"I'm\",\n",
       " 'not',\n",
       " 'really',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'the',\n",
       " 'product',\n",
       " 'anymore.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'charged',\n",
       " 'the',\n",
       " 'phone',\n",
       " 'completely',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'box',\n",
       " 'and',\n",
       " 'then',\n",
       " 'turned',\n",
       " 'it',\n",
       " 'on',\n",
       " '.',\n",
       " 'It',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Oneplus',\n",
       " 'logo',\n",
       " 'screen',\n",
       " 'but',\n",
       " 'did',\n",
       " 'nothing',\n",
       " 'after',\n",
       " 'that',\n",
       " '.',\n",
       " 'No',\n",
       " 'buttons',\n",
       " 'work',\n",
       " ',',\n",
       " 'no',\n",
       " 'combinations',\n",
       " 'of',\n",
       " 'any',\n",
       " 'buttons',\n",
       " 'do',\n",
       " 'anything',\n",
       " 'to',\n",
       " 'take',\n",
       " 'it',\n",
       " 'out',\n",
       " 'of',\n",
       " 'logo',\n",
       " 'screen',\n",
       " ',',\n",
       " 'it',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'even',\n",
       " 'turn',\n",
       " 'off',\n",
       " '.',\n",
       " 'Amazon',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'allow',\n",
       " 'return',\n",
       " 'until',\n",
       " 'technician',\n",
       " 'looks',\n",
       " 'at',\n",
       " 'the',\n",
       " 'phone',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'Oneplus',\n",
       " 'support',\n",
       " 'said',\n",
       " 'take',\n",
       " 'it',\n",
       " 'to',\n",
       " 'a',\n",
       " 'service',\n",
       " 'center',\n",
       " 'but',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'tell',\n",
       " 'me',\n",
       " 'the',\n",
       " 'closest',\n",
       " 'one',\n",
       " '.',\n",
       " 'Really',\n",
       " 'disappointed',\n",
       " 'in',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'support',\n",
       " 'form',\n",
       " 'both',\n",
       " 'companies',\n",
       " 'for',\n",
       " 'a',\n",
       " 'brand',\n",
       " 'new',\n",
       " 'product',\n",
       " 'and',\n",
       " 'release',\n",
       " '.',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'sure',\n",
       " 'they',\n",
       " 'will',\n",
       " 'now',\n",
       " 'try',\n",
       " 'to',\n",
       " 'push',\n",
       " 'a',\n",
       " 'replacement',\n",
       " 'but',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'not',\n",
       " 'really',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'the',\n",
       " 'product',\n",
       " 'anymore',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can split the function on a space (” “) to get all the words. \n",
    "# However, The problem with this is, we cannot extract punctuation marks like full stops, \n",
    "# and this simple parser will not be able to handle every single type of sentence.\n",
    "\n",
    "# Which is why we should use the word tokenizer provided by the NLTK library. This correctly identifies punctuation marks:\n",
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging\n",
    "\n",
    "Remove all punct\n",
    "Identify the parts of speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'NN'),\n",
       " ('charged', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('phone', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('out', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('box', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('then', 'RB'),\n",
       " ('turned', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('on', 'IN'),\n",
       " ('.', '.'),\n",
       " ('it', 'PRP'),\n",
       " ('went', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('oneplus', 'NN'),\n",
       " ('logo', 'NN'),\n",
       " ('screen', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('did', 'VBD'),\n",
       " ('nothing', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('.', '.'),\n",
       " ('no', 'DT'),\n",
       " ('buttons', 'NNS'),\n",
       " ('work', 'VBP'),\n",
       " (',', ','),\n",
       " ('no', 'DT'),\n",
       " ('combinations', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('buttons', 'NNS'),\n",
       " ('do', 'VBP'),\n",
       " ('anything', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('out', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('logo', 'NN'),\n",
       " ('screen', 'NN'),\n",
       " (',', ','),\n",
       " ('it', 'PRP'),\n",
       " ('wo', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('even', 'RB'),\n",
       " ('turn', 'VB'),\n",
       " ('off', 'RP'),\n",
       " ('.', '.'),\n",
       " ('amazon', 'NN'),\n",
       " ('wo', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('allow', 'VB'),\n",
       " ('return', 'NN'),\n",
       " ('until', 'IN'),\n",
       " ('technician', 'JJ'),\n",
       " ('looks', 'NNS'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('phone', 'NN'),\n",
       " ('?', '.'),\n",
       " ('?', '.'),\n",
       " ('?', '.'),\n",
       " ('oneplus', 'JJ'),\n",
       " ('support', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('take', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('a', 'DT'),\n",
       " ('service', 'NN'),\n",
       " ('center', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('could', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('tell', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('the', 'DT'),\n",
       " ('closest', 'JJS'),\n",
       " ('one', 'NN'),\n",
       " ('.', '.'),\n",
       " ('really', 'RB'),\n",
       " ('disappointed', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('lack', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('support', 'NN'),\n",
       " ('form', 'NN'),\n",
       " ('both', 'DT'),\n",
       " ('companies', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('brand', 'NN'),\n",
       " ('new', 'JJ'),\n",
       " ('product', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('release', 'NN'),\n",
       " ('.', '.'),\n",
       " ('i', 'JJ'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('sure', 'JJ'),\n",
       " ('they', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('now', 'RB'),\n",
       " ('try', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('push', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('replacement', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('i', 'JJ'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('really', 'RB'),\n",
       " ('interested', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('product', 'NN'),\n",
       " ('anymore', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# Now, let's get a tag associated with each and every token and see what part of speech these are.\n",
    "# Whether they're noun, pronoun, adverb, adjective etc.\n",
    "\n",
    "# By doing so, we can learn more about the constituents of a statement/tweet and see what kind of worlds are \n",
    "# present in it.\n",
    "w = word_tokenize(sentence)\n",
    "tokensLC = list()\n",
    "for words in w:\n",
    "    tokensLC.append(words.lower())\n",
    "\n",
    "nltk.pos_tag(tokensLC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of tags: http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('collaborate.v.01'), Synset('collaborate.v.02')]\n",
      "collaborate.v.01\n",
      "work together on a common enterprise of project\n",
      "collaborate.v.02\n",
      "cooperate as a traitor\n"
     ]
    }
   ],
   "source": [
    "# The Nltk has many great features, like finding the meaning of words, finding examples of words, \n",
    "# finding similar and opposite words etc. \n",
    "\n",
    "# You can see how useful these features would be if you were building like a search engine, or a text parser.\n",
    "\n",
    "# Let’s look at a few of these features.\n",
    "\n",
    "# The first thing you can do it, find the definition of any word.\n",
    "syn = wordnet.synsets(\"collaborate\")\n",
    "print(syn)\n",
    "print(syn[0].name())\n",
    "print(syn[0].definition())\n",
    "\n",
    "print(syn[1].name())\n",
    "print(syn[1].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('verify.v.01'), Synset('control.v.05'), Synset('verify.v.03'), Synset('affirm.v.02')]\n",
      "verify.v.01\n",
      "confirm the truth of\n",
      "control.v.05\n",
      "check or regulate (a scientific experiment) by conducting a parallel experiment or comparing with another standard\n"
     ]
    }
   ],
   "source": [
    "syn = wordnet.synsets(\"verify\")\n",
    "print(syn)\n",
    "print(syn[0].name())\n",
    "print(syn[0].definition())\n",
    "\n",
    "print(syn[1].name())\n",
    "print(syn[1].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the map showed roads and other features',\n",
       " 'generosity is one of his best characteristics']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn = wordnet.synsets(\"feature\")\n",
    "syn[0].examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = wordnet.synsets(\"set\")\n",
    "syn[1].examples()\n",
    "syn[2].examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book.n.01\n",
      "[Synset('publication.n.01')]\n",
      "**********************************************\n",
      "[Synset('appointment_book.n.01'), Synset('authority.n.07'), Synset('bestiary.n.01'), Synset('booklet.n.01'), Synset('catalog.n.01'), Synset('catechism.n.02'), Synset('copybook.n.01'), Synset('curiosa.n.01'), Synset('formulary.n.01'), Synset('phrase_book.n.01'), Synset('playbook.n.02'), Synset('pop-up_book.n.01'), Synset('prayer_book.n.01'), Synset('reference_book.n.01'), Synset('review_copy.n.01'), Synset('songbook.n.01'), Synset('storybook.n.01'), Synset('textbook.n.01'), Synset('tome.n.01'), Synset('trade_book.n.01'), Synset('workbook.n.01'), Synset('yearbook.n.01')]\n"
     ]
    }
   ],
   "source": [
    "# We can get words closer to a certain word using synsets, hypernyms and hyponymns.\n",
    "# Eg., we use the word \"Speak\" here. and what we get is the synonymns of speak.\n",
    "\n",
    "# Hymernym : a word with a broad meaning constituting a category into which words with more \n",
    "#            specific meanings fall\n",
    "\n",
    "# Hyponyms : each of two or more words having the same spelling or pronunciation but \n",
    "#            different meanings and origins \n",
    "\n",
    "syn = wordnet.synsets(\"book\")[0]\n",
    "print(syn.name())\n",
    "print(syn.hypernyms())\n",
    "print(\"**********************************************\")\n",
    "print(syn.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('infuriate.v.01.infuriate')\n",
      "Lemma('infuriate.v.01.exasperate')\n",
      "Lemma('infuriate.v.01.incense')\n",
      "Lemma('exasperating.s.01.exasperating')\n",
      "Lemma('exasperating.s.01.infuriating')\n",
      "Lemma('exasperating.s.01.maddening')\n",
      "Lemma('exasperating.s.01.vexing')\n"
     ]
    }
   ],
   "source": [
    "# Here in this example, we try to find the opposite words of \"good\"\n",
    "\n",
    "# lemma in NLTK is a canonical form of a word.\n",
    "syn = wordnet.synsets(\"infuriating\")\n",
    "\n",
    "for s in syn:\n",
    "    for l in s.lemmas():\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmas can be used to find all similar words:\n",
    "\n",
    "# And it heps us to reduce/substitute a set of words to one single word\n",
    "\n",
    "\n",
    "syn = wordnet.synsets(\"book\")\n",
    "print(\"*************************************************************************************\")\n",
    "print(\"Synonyms of book\")\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(syn)\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"*************************************************************************************\")\n",
    "print(\"Lemmas of book - Words that are similar to the word book and unique words in NLTK\")\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "for s in syn:\n",
    "    print(s.lemmas())\n",
    "print(\"-------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nltk comes inbuilt with a list of stop words for all main languages. \n",
    "# To see the stop words for English:\n",
    "\n",
    "\n",
    "stopwords.words('english')\n",
    "stopwords.words('german')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************\n",
      "Words with all stopwords\n",
      "-------------------------------------------------------------------------------------\n",
      "['AnalytixLabs', '-', 'leading', 'Capability', 'Building', 'and', 'Training', 'Solutions', 'Provider', '.', 'Our', 'courses', 'are', 'crafted', 'by', 'experts', 'to', 'keep', 'you', 'ahead', 'of', 'the', 'curve', 'in', 'industry', 'best', 'practices', '.', 'Case', 'study', 'based', 'modules', 'ensure', 'that', 'participants', 'learn', 'practical', 'applications', 'along', 'with', 'the', 'theoretical', 'concepts', '.', 'Further', 'to', 'this', ',', 'new', 'courses', 'are', 'continuously', 'launched', 'and', 'old', 'ones', 'keep', 'evolving', 'as', 'per', 'the', 'latest', 'and', 'upcoming', 'industry', 'trends', '.', 'High', 'degree', 'of', 'commitment', '&', 'personal', 'attention', 'is', 'given', 'through', 'small', 'batch', 'size', 'and', 'individual', 'counselling', '.', 'Hands-on', 'sessions', 'and', 'practice', 'assignments', 'on', 'real', 'life', 'business', 'datasets', 'are', 'included', 'to', 'ensure', 'assimilated', 'learning', '.']\n",
      "101\n",
      "-------------------------------------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Sentence is clean now - no stop words included\n",
      "-------------------------------------------------------------------------------------\n",
      "['AnalytixLabs', '-', 'leading', 'Capability', 'Building', 'Training', 'Solutions', 'Provider', '.', 'Our', 'courses', 'crafted', 'experts', 'keep', 'ahead', 'curve', 'industry', 'best', 'practices', '.', 'Case', 'study', 'based', 'modules', 'ensure', 'participants', 'learn', 'practical', 'applications', 'along', 'theoretical', 'concepts', '.', 'Further', ',', 'new', 'courses', 'continuously', 'launched', 'old', 'ones', 'keep', 'evolving', 'per', 'latest', 'upcoming', 'industry', 'trends', '.', 'High', 'degree', 'commitment', '&', 'personal', 'attention', 'given', 'small', 'batch', 'size', 'individual', 'counselling', '.', 'Hands-on', 'sessions', 'practice', 'assignments', 'real', 'life', 'business', 'datasets', 'included', 'ensure', 'assimilated', 'learning', '.']\n",
      "75\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# https://en.wikipedia.org/wiki/Cadet_Nurse_Corps\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "para = \"\"\"\n",
    "AnalytixLabs - leading Capability Building and Training Solutions Provider.\n",
    "\n",
    "Our courses are crafted by experts to keep you ahead of the curve in industry best practices. \n",
    "Case study based modules ensure that participants learn practical applications along with the theoretical concepts. \n",
    "\n",
    "Further to this, new courses are continuously launched and old ones keep evolving as per the latest and upcoming \n",
    "industry trends.\n",
    "\n",
    "High degree of commitment & personal attention is given through small batch size and individual counselling. \n",
    "Hands-on sessions and practice assignments on real life business datasets are included to ensure assimilated learning.\n",
    "\n",
    "\"\"\"\n",
    "words = word_tokenize(para)\n",
    "print(\"*************************************************************************************\")\n",
    "print(\"Words with all stopwords\")\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(words)\n",
    "print(len(words))\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "\n",
    "useful_words = [word for word in words if word not in stopwords.words('english')]\n",
    "print(\"*************************************************************************************\")\n",
    "print(\"Sentence is clean now - no stop words included\")\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(useful_words)\n",
    "print(len(useful_words))\n",
    "print(\"-------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quick': True, 'brown': True, 'fox': True}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how the Naive Bayes classifier expects the input\n",
    "\n",
    "def create_word_features(words):\n",
    "    useful_words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    my_dict = dict([(word, True) for word in useful_words])\n",
    "    return my_dict\n",
    "\n",
    "create_word_features([\"the\", \"quick\", \"brown\", \"quick\", \"a\", \"fox\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abbrevations and Words correction\n",
    "def clean_text(text):\n",
    "    import re\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:{}`+=~|.!?,'0-9]\", \"\", text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedWords = []\n",
    "for words in useful_words:\n",
    "    \n",
    "    cleanedWords.append(clean_text(words))\n",
    "cleanedWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
